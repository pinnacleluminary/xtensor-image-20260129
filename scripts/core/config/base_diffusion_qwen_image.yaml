job: extension
config:
  name: last
  process:
  - type: diffusion_trainer
    training_folder: /app/checkpoints
    device: cuda
    network:
      type: lora
      linear: 64
      linear_alpha: 128
    save:
      dtype: bf16
      save_every: 250
      max_step_saves_to_keep: 2
      save_format: diffusers
    datasets:
    - folder_path: /dataset/images
      caption_ext: txt
      cache_latents_to_disk: true
      resolution: [512, 768, 1024]
      is_reg: false
    train:
      batch_size: 4
      steps: 3000
      lr: 3e-5
      optimizer: adamw
      gradient_checkpointing: true
      gradient_accumulation: 1
      noise_scheduler: flowmatch
      timestep_type: weighted
      dtype: bf16
      cache_text_embeddings: true
      train_unet: true
      train_text_encoder: false
      optimizer_params:
        weight_decay: 1e-5
      ema_config:
        use_ema: true
        ema_decay: 0.995
      do_cfg: true
      cfg_scale: 5.0
    model:
      name_or_path: /cache/models
      arch: qwen_image
      quantize: true
      qtype: uint3|/cache/hf_cache/qwen_image_torchao_uint3.safetensors
      quantize_te: true
      qtype_te: qfloat8
      low_vram: false
meta:
  name: qwen_image_lora
  version: '1.0'